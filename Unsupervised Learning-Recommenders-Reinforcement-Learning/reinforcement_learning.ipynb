{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the goal is to find a function that maps the **state (s)** to an **action (a)**\n",
    "- uses a reward function to train model **R(s)**\n",
    "\n",
    "Applications\n",
    "- Controlling robots\n",
    "- factory optimization\n",
    "- financial (stock) trading\n",
    "- playing games (including video games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Return in Reinforcement Learning\n",
    "-  **discount factor (γ)**: modifies reward credited to each step, discounting rewards further in the future (often a number close to 1)\n",
    "- the **return** in reinforcement learning is the **sum of the rewards the system gets** but **weighted by the discount factor** -> rewards in the future are weighted by the discount factor raised to a higher power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Decisions: Policies in Reinforcement Learning\n",
    "- a policy function, **π(s) = a**, tells you what **action (a)** to take in a given **state (s)**\n",
    "\n",
    "- **goal**: fund a policy that tells you what action to take in every state (s) so as to maximize the return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Decision Process (MDP)\n",
    "- model for sequential decision making when outcomes are uncertain and partly controllable\n",
    "- \"Markov\" means that the future only depends on the current state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-Action Value Function (Q Function, Q*. Optimal Q Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a function typicall denoted by **Q(s, a)**\n",
    "    - gives a number equal to the return if you start in a **state (s)**, take the **action (a)** once, and behave optimally after that\n",
    "    - tells us how good it is to take action a in state s\n",
    "    - the best possible return from **state (s)** is **max Q(s, a)**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
