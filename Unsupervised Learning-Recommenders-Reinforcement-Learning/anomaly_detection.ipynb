{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flag example if p(X_test) < epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "- **Density Estimation** - a model to estimate the probability p(x) = p(x1) * p(x2)\n",
    "    - assumes statistically independent but should work fine even if they are dependent\n",
    "\n",
    "## Anomaly Detection Algorithm\n",
    "1. Choose n features zi that you think may be indicative of anomalous examples\n",
    "2. Fit parameters μ 1...n and σ^2 1...n\n",
    "    - μ_j = 1/m * sum(x)\n",
    "    - σ^2 = 1.m * sum(x - μj)\n",
    "3. Given a new example x, compute p(x) = \n",
    "4. Flag as anomaly if p(x) < epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- very useful to have a small number of anomolous examples to create a cross validation set and test set\n",
    "- train algorithm on training set (fit gaussian ditribution to these examples)\n",
    "- on cross validaiton set, can see how many are correctly flagged - can tune epsilon to be set higher or lower depnding on rate of false positives or false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Evaluation\n",
    "- fit model p(x) on training set\n",
    "- on a cross validation set, predict y = 1 if p(x) < epsilon, or y = 0 if p(x) >= epsilon\n",
    "- possible metrics\n",
    "    - true positive, false positive, false negative, true negative\n",
    "    - precision/recall\n",
    "    - F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomoly Detection vs Supervised Learning\n",
    "\n",
    "**Anomoly Detection**\n",
    "- very small number of positive examples (0-20), large number of negative examples\n",
    "- many \"types\" of abomalies\n",
    "- future anomalies may look nothing like previous anomolies\n",
    "\n",
    "**Supervised Learning**\n",
    "- large number of positive and negative examples\n",
    "- future positive examples likely to be similar to ones in training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features**\n",
    "- ideally transform features to be gaussian\n",
    "    - log(x1), log(x1+c), sqrt(x1) could all be potential transofmrations\n",
    "    - use a histogram to see shape\n",
    "- common problem: p(x) is comparable for normal ad anomalous examples  (i.e large for both)\n",
    "    - try to identify new feature that makes it distinct/different from other examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for estimating mean and variance of each feature\n",
    "def estimate_gaussian(X):\n",
    "    m, n = X.shape\n",
    "\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    var = sum((X-mu) ** 2) / X\n",
    "\n",
    "    return mu, var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* `select_threshold` - a loop that will try many different values of $\\varepsilon$ and select the best $\\varepsilon$ based on the $F_1$ score. \n",
    "\n",
    "* calculate the F1 score from choosing `epsilon` as the threshold and place the value in `F1`. \n",
    "\n",
    "  * Recall that if an example $x$ has a low probability $p(x) < \\varepsilon$, then it is classified as an anomaly. \n",
    "        \n",
    "  * Then, you can compute precision and recall by: \n",
    "   $$\n",
    "   prec = \\frac{tp}{tp+fp}\n",
    "   \\\\\n",
    "\n",
    "   rec = \\frac{tp}{tp+fn}$$ \n",
    "   \n",
    "   where\n",
    "    * $tp$ is the number of true positives: the ground truth label says it’s an anomaly and our algorithm correctly classified it as an anomaly.\n",
    "    * $fp$ is the number of false positives: the ground truth label says it’s not an anomaly, but our algorithm incorrectly classified it as an anomaly.\n",
    "    * $fn$ is the number of false negatives: the ground truth label says it’s an anomaly, but our algorithm incorrectly classified it as not being anomalous.\n",
    "\n",
    "  * The $F_1$ score is computed using precision ($prec$) and recall ($rec$) as follows:\n",
    "    $$F_1 = \\frac{2\\cdot prec \\cdot rec}{prec + rec}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for finding best threshold to use for selecting outliers based on results from validation set\n",
    "# uses F1 score\n",
    "\n",
    "def select_threshold(y_val, p_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
